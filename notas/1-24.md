#Intro to AI#
* Agent—entity which makes decisions for itself
    * Agent function—how the agent thinks (separate from how it's hooked up with the system)
    * Can make multiple decisions at once (think multiple units)
    * Emit data types, these aren't plugged in unless we do it
    * Exist in the digital realm not the physical world
* World—agents interact with physical through an environment
    * Agents need to sense the world
        * API calls
        * Robot sensors
    * Digital worlds have "representations"
* Rationality
    * Rational agents—produce good environment states
        * Selects action that will optimize performance given only the states it has seen and its internal knowledge
        * Allowed to make mistakes (only optimized for the past/current)
    * Performance metric evaluates this world
* Task Environment—all 4 of the below
    * Performance metric
    * Environment (description/software/interface)
    * Agent senses
    * Agent actions
* Types of TEs
    * Fully observable—agent has access to the complete environment
    * Partially observable—ex. Minesweeper
    * Deterministic—next state is completely dependent on past state + current action (if action can happen, it WILL)
    * Stochastic world—actions can be affected by probability
    * Static—world waits for agents to decide their actions
    * Dynamic—world does not wait
    * Single agent
    * Multi-agent—competitive, cooperative, communication
* Types of Agents
    * Simple reflex—all it does is reacts
    * Model-based reflex—maintains internal states and history of environment (but no forecasting)
    * Goal-based—is the current environment a "goal state" or not
    * Utility-based—utility function (internal performance metric) is used to assist agent and does not need to match the performance metric of the TE
    * Learning
        * learning element (some process that adjusts the agent)
        * action element (selects external actions)
        * critic (feedback)
        * problem generator (suggests novel experiences)
* World state
    * Agent senses $s_t$ at time $t$
    * Given $s_t$, agent produces an action $a_t$
    * Then $s_{t+1}$ is determined from both $s_t$ and $a_t$
* Worlds with known states
    * Make a graph of states of states that are connected by actions
    * Now the problem is a graph traversal problem
* Breadth First Search
    * Start at source vertex -> all neighbors ($1^{st}$ neighborhood $N_1$) -> neighbors of neighbors ($N_2$) and so on
    * Only explore simple paths (don't loop back in on themselves)
    * Shortest path found if performance metric is the same as the number of edges
    * Single-source path algorithm
* Depth First Search
    * Recursively probes deeper in paths
    * Only explore simple paths
    * Not guaranteed to find the shortest path
    * Depth-limited Search
        * Hyperparameter that limits how deep you can go (diameter of state space)
        * Can also iterate the diameter and rerun DFS
    * Also blind like BFS
* Dijkstra's Algorithm
    * "Shortest paths contain shortest paths"
    * If you find a faster path, forget the old path you "remembered" 
