# Lab assignment 3
* Can turn off the rendering <!-- ---> is a block comment I think
* 

# Classical search
* Blind search—BFS, DFS, Dijkstra's—may end up doing unnecessary work
* Informed search—A* adds a heuristic to estimate the cost
* But what if we don't care about the path?
* Or the world is too large?

# Optimization is life
* Objective surface—graph the objective function over axis of the attributes of candidates (Point (5, 17) would mean candidate 5 has an objective value of 17)
* From this you can move along the surface (walk down/uphill) to your goal (this movement = trajectory)
* Only finds local optima
* Hill climbing—gradient descent in discrete cases
* Greedy—can get stuck
* Generally easy to improve short-term
* Allow sideways movement on a plateau 
    * Thresholding—go for a certain amount then give up
    * Probability—flip weighted coin if you should continue
    * Momentum (if you're just coming off of a big descent, give yourself longer before giving up)
    * Random restarts—run multiple independent hill climbers

* Side note
    * Utility function—how good is this location
    * Goal function—are we at a goal or not

* Simulated annealing
    * Pick random state (cantidate)
    * If good, go there, repeat
    * If bad, flip a weighted coin, go or don't go
    * Start out _hot_ (willing to go to bad spots), end up _vanilla_ like other hill climbers

* Gradient descent
    * Continuous/piecewise continuous
    * Unless told otherwise, vectors are column vectors